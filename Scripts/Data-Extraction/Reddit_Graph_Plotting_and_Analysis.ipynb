{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sun\n",
      "[nltk_data]     Coliamco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sun Coliamco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to C:\\Users\\Sun\n",
      "[nltk_data]     Coliamco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sun\n",
      "[nltk_data]     Coliamco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Sun\n",
      "[nltk_data]     Coliamco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import bigrams\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the files in this block\n",
    "\n",
    "data_frame_test = pd.read_csv(\"../../Data/Analysis_ready/clean_test_reddit.csv\")\n",
    "data_frame_odi = pd.read_csv(None)\n",
    "data_frame_t20 = pd.read_csv(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post_id</th>\n",
       "      <th>Id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Score</th>\n",
       "      <th>No_comments</th>\n",
       "      <th>Body</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pre-processed_body</th>\n",
       "      <th>Vader_Pre-processed_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>1f0syen</td>\n",
       "      <td>2024-08-25 20:04:21</td>\n",
       "      <td>NoQuestion4045</td>\n",
       "      <td>2445</td>\n",
       "      <td>281</td>\n",
       "      <td>Bangladesh beats Pakistan for the first ever i...</td>\n",
       "      <td>Post</td>\n",
       "      <td>bangladesh beat pakistan first ever test cricket</td>\n",
       "      <td>Bangladesh beats Pakistan for the first ever i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>lju4ld6</td>\n",
       "      <td>2024-08-25 20:07:28</td>\n",
       "      <td>deleted</td>\n",
       "      <td>1151</td>\n",
       "      <td>0</td>\n",
       "      <td>Fort Rawalpindi, yet to be captured, by the ho...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>fort rawalpindi yet capture home side</td>\n",
       "      <td>Fort Rawalpindi , yet to be captured , by the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>lju9bzy</td>\n",
       "      <td>2024-08-25 20:58:53</td>\n",
       "      <td>mofucker20</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>That stat is so ridiculous. What’s even the us...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>stat ridiculous whats even use home ground hav...</td>\n",
       "      <td>That stat is so ridiculous . What ’ s even the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>ljubwki</td>\n",
       "      <td>2024-08-25 21:24:17</td>\n",
       "      <td>SquiffyRae</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>Part of the problem is Pindi is such a highway...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>part problem pindi highway road there's always...</td>\n",
       "      <td>Part of the problem is Pindi is such a highway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>ljvk09z</td>\n",
       "      <td>2024-08-26 02:17:08</td>\n",
       "      <td>deleted</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>It's particularly risky for a team like Pakist...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>particularly risky team like pakistan tendency...</td>\n",
       "      <td>It's particularly risky for a team like Pakist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post_id       Id                 Time          Author  Score  No_comments  \\\n",
       "0  1f0syen  1f0syen  2024-08-25 20:04:21  NoQuestion4045   2445          281   \n",
       "1  1f0syen  lju4ld6  2024-08-25 20:07:28         deleted   1151            0   \n",
       "2  1f0syen  lju9bzy  2024-08-25 20:58:53      mofucker20    289            0   \n",
       "3  1f0syen  ljubwki  2024-08-25 21:24:17      SquiffyRae    173            0   \n",
       "4  1f0syen  ljvk09z  2024-08-26 02:17:08         deleted     48            0   \n",
       "\n",
       "                                                Body     Type  \\\n",
       "0  Bangladesh beats Pakistan for the first ever i...     Post   \n",
       "1  Fort Rawalpindi, yet to be captured, by the ho...  Comment   \n",
       "2  That stat is so ridiculous. What’s even the us...  Comment   \n",
       "3  Part of the problem is Pindi is such a highway...  Comment   \n",
       "4  It's particularly risky for a team like Pakist...  Comment   \n",
       "\n",
       "                                  Pre-processed_body  \\\n",
       "0   bangladesh beat pakistan first ever test cricket   \n",
       "1              fort rawalpindi yet capture home side   \n",
       "2  stat ridiculous whats even use home ground hav...   \n",
       "3  part problem pindi highway road there's always...   \n",
       "4  particularly risky team like pakistan tendency...   \n",
       "\n",
       "                            Vader_Pre-processed_body  \n",
       "0  Bangladesh beats Pakistan for the first ever i...  \n",
       "1  Fort Rawalpindi , yet to be captured , by the ...  \n",
       "2  That stat is so ridiculous . What ’ s even the...  \n",
       "3  Part of the problem is Pindi is such a highway...  \n",
       "4  It's particularly risky for a team like Pakist...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph: Interaction between formats for the most active members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the Top N most active members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and sort comment count for non-deleted users\n",
    "\n",
    "# test \n",
    "test_comment_count_by_author = data_frame_test.groupby('Author').size().reset_index(name='Comment/Post_Count')\n",
    "test_comment_count_by_author = test_comment_count_by_author.sort_values(by='Comment/Post_Count', ascending=False)\n",
    "test_comment_count_by_author = test_comment_count_by_author[test_comment_count_by_author['Author'] != \"deleted\"]\n",
    "\n",
    "odi\n",
    "odi_comment_count_by_author = data_frame_odi.groupby('Author').size().reset_index(name='Comment/Post_Count')\n",
    "odi_comment_count_by_author = odi_comment_count_by_author.sort_values(by='Comment/Post_Count', ascending=False)\n",
    "odi_comment_count_by_author = odi_comment_count_by_author[odi_comment_count_by_author['Author'] != \"deleted\"]\n",
    "\n",
    "# t20\n",
    "t20_comment_count_by_author = data_frame_t20.groupby('Author').size().reset_index(name='Comment/Post_Count')\n",
    "t20_comment_count_by_author = t20_comment_count_by_author.sort_values(by='Comment/Post_Count', ascending=False)\n",
    "t20_comment_count_by_author = t20_comment_count_by_author[t20_comment_count_by_author['Author'] != \"deleted\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_count = 50\n",
    "\n",
    "top_n_test_author_list = test_comment_count_by_author['Author'].head(head_count).to_list()\n",
    "top_n_odi_author_list  = odi_comment_count_by_author['Author'].head(head_count).to_list()\n",
    "top_n_t20_author_list  = t20_comment_count_by_author['Author'].head(head_count).to_list()\n",
    "\n",
    "top_n_odi_author_list = []\n",
    "top_n_t20_author_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VisRock',\n",
       " 'abettertomorrow47',\n",
       " 'Classymuch',\n",
       " 'crashbandicoochy',\n",
       " 'mongrelbifana']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_test_author_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the post and comments by the top users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prevent some users has barely drop off the top rank, I have included all top users in all top 3 group for filtering\n",
    "top_n_users_set = set()\n",
    "top_n_users_set.update(top_n_test_author_list)\n",
    "top_n_users_set.update(top_n_odi_author_list)\n",
    "top_n_users_set.update(top_n_t20_author_list)\n",
    "\n",
    "to_n_author_content_test = data_frame_test[data_frame_test['Author'].isin(top_n_users_set)]\n",
    "to_n_author_content_odi  = data_frame_odi[data_frame_odi['Author'].isin(top_n_users_set)]\n",
    "to_n_author_content_t20  = data_frame_t20[data_frame_t20['Author'].isin(top_n_users_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post_id</th>\n",
       "      <th>Id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Score</th>\n",
       "      <th>No_comments</th>\n",
       "      <th>Body</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pre-processed_body</th>\n",
       "      <th>Vader_Pre-processed_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>ljuphhc</td>\n",
       "      <td>2024-08-25 23:15:35</td>\n",
       "      <td>confused_brown_dude</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>I wasn’t ready for this 😭</td>\n",
       "      <td>Comment</td>\n",
       "      <td>wasnt ready</td>\n",
       "      <td>I wasn ’ t ready for this 😭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>ljuppbl</td>\n",
       "      <td>2024-08-25 23:17:07</td>\n",
       "      <td>confused_brown_dude</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>I can’t get past the idiot thing 🤣, why does i...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>cant get past idiot thing hit hard</td>\n",
       "      <td>I can ’ t get past the idiot thing 🤣 , why doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>ljuv8bq</td>\n",
       "      <td>2024-08-25 23:53:59</td>\n",
       "      <td>Medical_Turing_Test</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>As a Fawad Alam truther it's important to note...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>fawad alam truther important note ss sensational</td>\n",
       "      <td>As a Fawad Alam truther it's important to note...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>ljv3br3</td>\n",
       "      <td>2024-08-26 00:42:41</td>\n",
       "      <td>Medical_Turing_Test</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Probably. But Fawad is ancient.\\n\\nUnlikely. S...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>probably fawad ancient unlikely saim ayub scor...</td>\n",
       "      <td>Probably . But Fawad is ancient . Unlikely . S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1f0syen</td>\n",
       "      <td>ljv8d1c</td>\n",
       "      <td>2024-08-26 01:11:04</td>\n",
       "      <td>Medical_Turing_Test</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.espncricinfo.com/series/quaid-e-az...</td>\n",
       "      <td>Comment</td>\n",
       "      <td>please stop embarrassing</td>\n",
       "      <td>Please stop embarrassing yourself</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Post_id       Id                 Time               Author  Score  \\\n",
       "36  1f0syen  ljuphhc  2024-08-25 23:15:35  confused_brown_dude      5   \n",
       "65  1f0syen  ljuppbl  2024-08-25 23:17:07  confused_brown_dude     30   \n",
       "72  1f0syen  ljuv8bq  2024-08-25 23:53:59  Medical_Turing_Test     12   \n",
       "74  1f0syen  ljv3br3  2024-08-26 00:42:41  Medical_Turing_Test     10   \n",
       "76  1f0syen  ljv8d1c  2024-08-26 01:11:04  Medical_Turing_Test      4   \n",
       "\n",
       "    No_comments                                               Body     Type  \\\n",
       "36            0                          I wasn’t ready for this 😭  Comment   \n",
       "65            0  I can’t get past the idiot thing 🤣, why does i...  Comment   \n",
       "72            0  As a Fawad Alam truther it's important to note...  Comment   \n",
       "74            0  Probably. But Fawad is ancient.\\n\\nUnlikely. S...  Comment   \n",
       "76            0  https://www.espncricinfo.com/series/quaid-e-az...  Comment   \n",
       "\n",
       "                                   Pre-processed_body  \\\n",
       "36                                        wasnt ready   \n",
       "65                 cant get past idiot thing hit hard   \n",
       "72   fawad alam truther important note ss sensational   \n",
       "74  probably fawad ancient unlikely saim ayub scor...   \n",
       "76                           please stop embarrassing   \n",
       "\n",
       "                             Vader_Pre-processed_body  \n",
       "36                        I wasn ’ t ready for this 😭  \n",
       "65  I can ’ t get past the idiot thing 🤣 , why doe...  \n",
       "72  As a Fawad Alam truther it's important to note...  \n",
       "74  Probably . But Fawad is ancient . Unlikely . S...  \n",
       "76                  Please stop embarrassing yourself  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_n_author_content_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15105, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_n_author_content_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to import networkx\n",
    "import networkx as nx\n",
    "\n",
    "# here are the three main format\n",
    "test = \"Test\"\n",
    "odi  = \"ODI\"\n",
    "t20  = \"T20\"\n",
    "\n",
    "activity_graph = nx.DiGraph()\n",
    "activity_graph.add_node(test)\n",
    "activity_graph.add_node(odi)\n",
    "activity_graph.add_node(t20)\n",
    "\n",
    "user_check_set = set()\n",
    "\n",
    "# to_n_author_content_test\n",
    "# acc = author comment count\n",
    "# test:\n",
    "acc_test_list = to_n_author_content_test.groupby('Author').size().reset_index(name='Comment/Post_Count')\n",
    "\n",
    "for index, row in acc_test_list.iterrows():\n",
    "    \n",
    "    user = row['Author']\n",
    "    if user not in user_check_set:\n",
    "        user_check_set.add(user)\n",
    "        activity_graph.add_node(user)\n",
    "    \n",
    "    activity_graph.add_edge(user, test, weight=row['Comment/Post_Count'])\n",
    "\n",
    "# ODI\n",
    "acc_odi_list = to_n_author_content_odi.groupby('Author').size().reset_index(name='Comment/Post_Count')\n",
    "\n",
    "for index, row in acc_odi_list.iterrows():\n",
    "    \n",
    "    user = row['Author']\n",
    "    if user not in user_check_set:\n",
    "        user_check_set.add(user)\n",
    "        activity_graph.add_node(user)\n",
    "    \n",
    "    activity_graph.add_edge(user, odi, weight=row['Comment/Post_Count'])\n",
    "\n",
    "# ODI\n",
    "acc_t20_list = to_n_author_content_t20.groupby('Author').size().reset_index(name='Comment/Post_Count')\n",
    "\n",
    "for index, row in acc_t20_list.iterrows():\n",
    "    \n",
    "    user = row['Author']\n",
    "    if user not in user_check_set:\n",
    "        user_check_set.add(user)\n",
    "        activity_graph.add_node(user)\n",
    "    \n",
    "    activity_graph.add_edge(user, t20, weight=row['Comment/Post_Count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.readwrite.write_graphml(activity_graph, 'test_graph.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
